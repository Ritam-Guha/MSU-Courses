{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. List all the selection mechanisms, both parent and survivor, that you have learned about and discuss their properties.**  \n",
    "\n",
    "**Response:** Selection mechanisms in evoluationary computation are defined as the ways of choosing parent solutions (parent selection) for recombinations in order to create child solutions or choosing the solutions to pass to the next generation (sutvivor selection). Selection is a very important step as it can significantly influence the search process. In the following section, different selection mechanisms are discussed in detail:\n",
    "\n",
    "**1. Fitness Proportional Selection:** In this type of selection, the fitness values of the solutions are used as a guidance metric to choose the candidate solutions.\n",
    "\n",
    "    - **Roulette Wheel Selection (RWS):** Every candidate solution is assigned a fitness score by the fitness function and a selection probablity is calculated for each of the solutions using these scores. Visually it can be assumed to form a roulette wheel (used in casinos) where each solution gets a portion of the wheel according to its fitness measure. The solutions are then probabilisitcially sampled from the wheel. A higher fitness value leads to a higher probability of selection for a particular candidate solution. The limitation of RWS is that every time we need to sample a solution, we need to call a random number generator which is quite computationally expensive in most of the times.\n",
    "    \n",
    "    - **Stochastic Universal Sampling:** In Stochastic Universal Sampling, a roulette wheel is again created according to the fitness scores of the candidate solutions. But the sampling process is different. We start with an origin point $O$ on the wheel which is randomly selected in the range $[0, \\frac{1}{M})$ where $M$ is the number of solutions. Origin point can be represented as the initial draw on the roulette wheel. From origin, a number of draws are sampled with a step size of $\\frac{1}{M}$. A solution is selected equal to the number of draws in its range. It gets rid of the major limitation of RWS as it provides lesser variance and does not require calls to random number generator after just the initial origin sampling. \n",
    "    \n",
    "**Limitation:** The problem with Fitness Proportional Selection is that as the population evolve, their fitness values increase and the gap in the fitness scores keeps on decreasing. So, after some time, the selection pressure reduces and the best and worst solutions start having similar probabilities of becoming parents. \n",
    "**Solution:** \n",
    "    - Scale the relative fitness in such a way that maintains a proper selection pressure throughout the generations.\n",
    "    - Use other selection procedures (like Elitist or Rank-based selection)\n",
    "    \n",
    "    \n",
    "**2. Rank-based Selection:** It ranks the candidate solutions according to their fitness scores and uses the best performing solutions as parents.\n",
    "\n",
    "    - **Tournament Selection:** From the pool of all the solutions, Tournament Selection randomly samples $k$ solutions and perform a tournament among this new population of $k$ solutions. The candidate solution with best fitness in this tournament, wins the tournament and gets to be a parent. The value of $k$ is very important here. If it is too less, it leads to weak selection pressure and if it is large, it leads to strong selection pressure. The population should be shuffled properly to avoid inadvertent ordering of the population according to their fitness values.\n",
    "    \n",
    "    \n",
    "**3. Elitist Selection:** In this kind of selection, top a few percentage of the solutions under consiuderation are passed on to the next generation. There are some different rules of selecting the population.\n",
    "\n",
    "    - $(\\mu, \\lambda):$ Here $\\lambda$ child solutions are created from $\\mu$ parent solutions (where $\\lambda>\\mu$) and the best $\\mu$ child solutions replace the parents.\n",
    "    \n",
    "    - $(\\mu+\\lambda):$ Similar to the previous case,  $\\lambda$ child solutions are created from $\\mu$ parent solutions. But now all ($\\lambda$ child + $\\mu$ parent) solutions are considered and the top $\\mu$ solutions are selected to replace the parent population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2. Let S1={1\\*\\*\\*10\\*\\*00\\*\\*} and S2={\\*\\*\\*1\\*01\\*\\*\\*\\*\\*} be two schemata**\n",
    "1. Give the order and the defining length of S1 and S2.\n",
    "\n",
    "**Response:** Order is the number of non-$*$ characters in the schemata and defining length is the distance between the first and last non-$*$ characters in the schemata. So, according to the definition:\n",
    "\n",
    "$O(S1)$ = 5, $O(S2)$ = 3\n",
    "\n",
    "$\\Delta(S1)$ = 9, $\\Delta(S2)$ = 3 \n",
    "\n",
    "2. What is the probability for one-point crossover with crossover rate $P_c$ that crossover breaks S1, or S2? (i.e., the probability that the child created by the operator does not belong to the given schema, assuming each is crossed over with a mate that does not match it in any of the positions with a value specified.)\n",
    "\n",
    "**Response:** A single-point crossover can disrupt a schema $S$ in $\\Delta(S)$ positions out of $L-1$ positions where $L$ is the length of the schema. For each instance of the schema, the proability of disruption through this crossover is: $\\frac{\\Delta(S)}{L-1}$. So, the final probability of crossover breaks is: $\\frac{\\Delta(S)}{L-1} P_c$.\n",
    "\n",
    "Probability of disruption through single-point crossover for $S1$: $\\frac{9}{11} P_c$  \n",
    "Probability of disruption through single-point crossover for $S2$: $\\frac{3}{11} P_c$\n",
    "\n",
    "3. What is the probability that mutation with mutation rate pm breaks S1, or S2?\n",
    "\n",
    "**Response:** A mutation can change the fixed bits of the schema to disrupt it and every position has a proability of mutation as $P_m$. So, the probability that mutation breaks a schema S is: $P_m ^ {O(S)}$.\n",
    "\n",
    "Probablity of disruption through mutation for $S1$: $P_m ^ 5$  \n",
    "Probablity of disruption through mutation for $S2$: $P_m ^ 3$\n",
    "\n",
    "4. What is the probability that S1 or S2 survive the application of both crossover and mutation?\n",
    "\n",
    "**Response:** The probability that a schema S survives through crossover and mutation can be expressed as:   \n",
    "1 - (Probability that crossover breaks S) - (Probability that mutation breaks S).\n",
    "\n",
    "Probability that $S1$ survives: 1 - $\\frac{9}{11} P_c$ - $P_m ^ 5$  \n",
    "Probability that $S2$ survives: 1 - $\\frac{3}{11} P_c$ - $P_m ^ 3$\n",
    "\n",
    "5. Is it correct to call one of these two schemata a “building block”? Explain why, or why not.\n",
    "**Response:** Short, low-order and highly fit schemata are trated as building blocks. In this problem, if we keep aside the fitness measure, we can see that $S2$ has a low order of $3$ and a low length of $3$. So, $S2$ is a better candidate than $S1$ to be a \"building block\" of the approach. From Schema theorem, we can say that the schema $S2$ has better chances of survival and it should be nurtured properly to create more novel solutions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
